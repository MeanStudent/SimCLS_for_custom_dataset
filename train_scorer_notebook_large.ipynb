{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45ecab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Dec 17 07:35:00 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    52W / 400W |      0MiB / 40960MiB |     27%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93400c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class my_args:\n",
    "    def __init__(self, generator_name, dataset_name, dataset_percent, num_cands, scorer_path):\n",
    "        self.generator_name = generator_name\n",
    "        self.dataset_name = dataset_name\n",
    "        self.num_cands = dataset_percent\n",
    "        self.dataset_percent = num_cands\n",
    "        self.scorer_path = scorer_path\n",
    "args = my_args('tuned_t5_model','clean_covid.csv',16,10, 'cache/22-12-16-0/scorer.bin') # 10 stands for 10% of dataset are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d0f770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tokenize dataset--------------------\n",
      "100%|███████████████████████████████████████████| 66/66 [00:26<00:00,  2.51ba/s]\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:03<00:00,  2.81ba/s]\n",
      "100%|█████████████████████████████████████████████| 9/9 [00:03<00:00,  2.69ba/s]\n",
      "start generate training candidates!--------------------------------------------------\n",
      "start generate validation candidates!--------------------------------------------------\n",
      "start generate testing candidates!--------------------------------------------------\n",
      "start saving candidate summariesch_index: 128, last epoch time: 14 sec\n"
     ]
    }
   ],
   "source": [
    "!python gen_candidate.py --generator_name {args.generator_name} --dataset_name {args.dataset_name} --dataset_percent {args.dataset_percent} --num_cands {args.num_cands} --cand_gen_batch 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f475f5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing val candidates for training\n",
      "finish\n",
      "start processing train candidates for training\n",
      "finish\n",
      "start processing test candidates for training\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# create folder for processed dataset\n",
    "os.makedirs(f'candidates/{args.generator_name}_{args.num_cands}_processed/diverse/train', exist_ok=True)\n",
    "os.makedirs(f'candidates/{args.generator_name}_{args.num_cands}_processed/diverse/test', exist_ok=True)\n",
    "os.makedirs(f'candidates/{args.generator_name}_{args.num_cands}_processed/diverse/val', exist_ok=True)\n",
    "\n",
    "# process candidates\n",
    "print('start processing val candidates for training')\n",
    "!python preprocess.py --src_dir candidates/{args.generator_name}_{args.num_cands}/diverse --tgt_dir candidates/{args.generator_name}_{args.num_cands}_processed/diverse/val --split 'val' --cand_num {args.num_cands}\n",
    "print('start processing train candidates for training')\n",
    "!python preprocess.py --src_dir candidates/{args.generator_name}_{args.num_cands}/diverse --tgt_dir candidates/{args.generator_name}_{args.num_cands}_processed/diverse/train --split 'train' --cand_num {args.num_cands}\n",
    "print('start processing test candidates for training')\n",
    "!python preprocess.py --src_dir candidates/{args.generator_name}_{args.num_cands}/diverse --tgt_dir candidates/{args.generator_name}_{args.num_cands}_processed/diverse/test --split 'test' --cand_num {args.num_cands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f63fb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make necessary dirs for training\n",
    "if not os.path.exists('cache'):\n",
    "    os.makedirs('cache')\n",
    "\n",
    "training_data_path = f'candidates/{args.generator_name}_{args.num_cands}_processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7afe3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████| 615/615 [00:00<00:00, 643kB/s]\n",
      "Downloading: 100%|█████████████████████████| 5.07M/5.07M [00:00<00:00, 20.4MB/s]\n",
      "Downloading: 100%|█████████████████████████| 9.10M/9.10M [00:00<00:00, 30.5MB/s]\n",
      "Downloading: 100%|█████████████████████████| 1.12G/1.12G [00:14<00:00, 76.2MB/s]\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Namespace(accumulate_step=12, batch_size=1, cand_weight=1, cuda=True, dataset='candidates/tuned_t5_model_16_processed', datatype='diverse', encode_mode=None, epoch=5, evaluate=False, gold_margin=0, gold_weight=1, gpuid=[0], grad_norm=0, log=True, margin=0.01, max_len=120, max_lr=0.002, max_num=16, model_pt='', model_type='xlm-roberta-base', no_gold=False, port=12355, pretrained=None, report_freq=100, scale=1, seed=970903, warmup_steps=10000)\n",
      "\n",
      "ReRanker(\n",
      "  (encoder): XLMRobertaModel(\n",
      "    (embeddings): XLMRobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): XLMRobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): XLMRobertaPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9836, 0.9009, 0.8333, 0.9991, 0.9983, 0.9987, 0.9984, 0.9990, 0.9990,\n",
      "         0.7424]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9990], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 100, avg loss: 1.523841\n",
      "learning rate: 0.000000\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9993, 0.9993, 0.9992, 0.9993, 0.9990, 0.8180, 0.9993, 0.9989, 0.9990,\n",
      "         0.8829]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9994], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 200, avg loss: 1.483508\n",
      "learning rate: 0.000000\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.8321, 0.9992, 0.9991, 0.9994, 0.9994, 0.8509, 0.9994, 0.9995, 0.9993,\n",
      "         0.8753]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9995], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 300, avg loss: 1.398174\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9992, 0.9995, 0.9996, 0.9995, 0.6667, 0.9993, 0.9992, 0.9953, 0.9996,\n",
      "         0.9996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9996], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 400, avg loss: 1.359604\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9994, 0.9996, 0.9997, 0.9987, 0.9997, 0.9994, 0.9991, 0.9942, 0.9994,\n",
      "         0.9996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9996], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 500, avg loss: 1.322839\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9991, 0.9133, 0.9942, 0.9997, 0.9998, 0.9998, 0.9998, 0.9998, 0.9965,\n",
      "         0.9997]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9992], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 600, avg loss: 1.278294\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9982, 0.9996, 0.9996, 0.9996, 0.9996, 0.9997, 0.9996, 0.9977, 0.9996,\n",
      "         0.9996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9995], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 700, avg loss: 1.260589\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9998, 0.9994, 0.9997, 0.9957, 0.9998, 0.9998, 0.9618, 0.9996,\n",
      "         0.9977]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9997], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 800, avg loss: 1.240049\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.8899, 0.8928, 0.8902, 0.8930, 0.8946, 0.8999, 0.8959, 0.8927, 0.8912,\n",
      "         0.9248]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.8909], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 900, avg loss: 1.238534\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9982, 0.9771, 0.9979, 0.9998, 0.9989, 0.9988, 0.9985, 0.9991, 0.9998,\n",
      "         0.9989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9996], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1000, avg loss: 1.230282\n",
      "learning rate: 0.000002\n",
      "\n",
      "test similarity: [0.9997885  0.9997714  0.9998537  0.9998714  0.999783   0.99978757\n",
      " 0.99979573 0.99976516 0.9998347  0.99979067 0.99980193 0.99975806\n",
      " 0.99983895 0.9998219  0.9998474  0.9997765 ]\n",
      "test similarity: [0.9998581  0.9998519  0.999852   0.99984723 0.99986506 0.99990153\n",
      " 0.9998638  0.99988383 0.9998923  0.99981666 0.99987996 0.9998837\n",
      " 0.99973005 0.9998991  0.9998581  0.9998666 ]\n",
      "rouge-1: 0.12569857764837145, rouge-2: 0.008648368164579067, rouge-L: 0.1048796670576498\n",
      "best - epoch: 0, batch: 999\n",
      "val rouge: 0.079742\n",
      "id: 0\n",
      "similarity: tensor([[0.9765, 0.9998, 0.8463, 0.9998, 0.9796, 0.9732, 0.9996, 0.9998, 0.9999,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9995], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1100, avg loss: 1.221308\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9996, 0.9995, 0.9856, 0.9988, 0.9996, 0.9995, 0.9996, 0.9977, 0.9996,\n",
      "         0.9996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9995], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1200, avg loss: 1.224476\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9974, 0.9850, 0.9975, 0.9987, 0.9970, 0.9968, 0.9969, 0.9969, 0.9970,\n",
      "         0.9988]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9980], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1300, avg loss: 1.219418\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9999, 0.9998, 0.9992, 0.9999, 0.9999, 0.9995, 0.9864,\n",
      "         0.9997]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1400, avg loss: 1.214286\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9995, 0.9999, 0.9995, 0.9998, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1500, avg loss: 1.206936\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9995, 0.9870, 0.9996, 0.9996, 0.9904, 0.9995, 0.9995, 0.9997, 0.9996,\n",
      "         0.9987]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9934], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1600, avg loss: 1.215331\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9998, 0.9999, 0.9843, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9993], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1700, avg loss: 1.213514\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9993, 0.9998, 0.9998, 0.9998, 0.9999, 0.9998, 0.9998, 0.9997,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9997], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1800, avg loss: 1.203657\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9997, 0.9999, 0.9909, 0.9999, 0.9998, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1900, avg loss: 1.208843\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9999, 0.9998, 0.9996, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9986]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2000, avg loss: 1.208932\n",
      "learning rate: 0.000004\n",
      "\n",
      "test similarity: [0.9998701  0.9998861  0.99989027 0.99988985 0.99986684 0.9998557\n",
      " 0.99988467 0.9998812  0.9998897  0.9998639  0.9998614  0.9998756\n",
      " 0.99989414 0.9998618  0.99989563 0.99984443]\n",
      "test similarity: [0.99992883 0.99992627 0.99992484 0.99992496 0.9999304  0.99993515\n",
      " 0.999929   0.9999286  0.99992734 0.9999221  0.999927   0.99993414\n",
      " 0.99991626 0.99993616 0.99992883 0.9999281 ]\n",
      "rouge-1: 0.11607107238692418, rouge-2: 0.007626268851139983, rouge-L: 0.09873649517571496\n",
      "val rouge: 0.074145\n",
      "id: 0\n",
      "similarity: tensor([[0.9994, 0.9993, 0.9994, 0.9994, 0.9986, 0.9993, 0.9939, 0.9994, 0.9993,\n",
      "         0.9993]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9994], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2100, avg loss: 1.205777\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9997, 0.9997, 0.9997, 0.9997, 0.9996, 0.9997, 0.9997, 0.9998,\n",
      "         0.9997]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9996], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2200, avg loss: 1.204910\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9998, 0.9999, 0.9880, 0.9998, 0.9999, 0.9996, 0.9999, 0.9998,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2300, avg loss: 1.203587\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9787, 0.9775, 0.9798, 0.9777, 0.9788, 0.9789, 0.9784, 0.9784, 0.9787,\n",
      "         0.9784]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9779], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2400, avg loss: 1.201627\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9997, 0.9998, 0.9989, 0.9998, 0.9998, 0.9998, 0.9928,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2500, avg loss: 1.204212\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9997, 0.9906, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2600, avg loss: 1.205690\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9998, 0.9998, 0.9822, 0.9999, 0.9724, 0.9999, 0.9999, 0.9999,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2700, avg loss: 1.205270\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9996, 0.9998, 0.9998, 0.9999, 0.9996, 0.9998, 0.9998, 0.9994, 0.9998,\n",
      "         0.9928]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9992], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2800, avg loss: 1.201662\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9982, 0.9983, 0.9980, 0.9983, 0.9981, 0.9981, 0.9983, 0.9982, 0.9985,\n",
      "         0.9858]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9990], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2900, avg loss: 1.202607\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9996, 0.9994, 0.9994, 0.9993, 0.9994, 0.9993, 0.9994, 0.9995, 0.9993,\n",
      "         0.9995]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9994], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3000, avg loss: 1.204954\n",
      "learning rate: 0.000006\n",
      "\n",
      "test similarity: [0.99984694 0.9998411  0.9998548  0.99984705 0.999846   0.9998345\n",
      " 0.99982333 0.999836   0.9998559  0.9997917  0.99983364 0.9998557\n",
      " 0.9998461  0.9997965  0.9998377  0.99982196]\n",
      "test similarity: [0.99991983 0.9999312  0.99992067 0.9999235  0.99992806 0.99991935\n",
      " 0.9999226  0.9999156  0.99992394 0.9999216  0.9999269  0.99992996\n",
      " 0.99992454 0.9999228  0.99991983 0.9999291 ]\n",
      "rouge-1: 0.09999372786195455, rouge-2: 0.0073674052050942155, rouge-L: 0.08775434099750347\n",
      "val rouge: 0.065038\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9994, 0.9801,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3100, avg loss: 1.201588\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9998, 0.9998, 0.9998, 0.9998, 0.9997, 0.9999, 0.9998, 0.9998,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3200, avg loss: 1.201872\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9887, 0.9999, 0.9996,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3300, avg loss: 1.202439\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9997, 0.9999, 0.9998, 0.9999, 0.9999, 0.9999, 0.9998, 0.9998,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3400, avg loss: 1.203893\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9999,\n",
      "         0.9943]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9996], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3500, avg loss: 1.203114\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9998, 0.9998, 0.9998, 0.9997, 0.9956, 0.9998, 0.9998, 0.9997,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3600, avg loss: 1.201262\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9995, 0.9999,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3700, avg loss: 1.203359\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9949, 0.9943, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3800, avg loss: 1.202105\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9993, 0.9993, 0.9993, 0.9993, 0.9992, 0.9921, 0.9993, 0.9992, 0.9993,\n",
      "         0.9992]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9993], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3900, avg loss: 1.200700\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9917, 0.9997, 0.9999,\n",
      "         0.9997]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4000, avg loss: 1.201813\n",
      "learning rate: 0.000008\n",
      "\n",
      "test similarity: [0.9999189  0.99992096 0.9999237  0.9999229  0.99992067 0.9999179\n",
      " 0.9999197  0.99992037 0.999923   0.999919   0.9999209  0.9999202\n",
      " 0.99992234 0.99992025 0.99992263 0.9999223 ]\n",
      "test similarity: [0.9999366  0.9999374  0.99994165 0.9999419  0.9999228  0.9999402\n",
      " 0.9999346  0.99994004 0.99994457 0.9999441  0.9999435  0.99993485\n",
      " 0.99990356 0.9999366  0.9999366  0.99994355]\n",
      "rouge-1: 0.12126404031556465, rouge-2: 0.007955118141416568, rouge-L: 0.10054019783353373\n",
      "val rouge: 0.076586\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9998, 0.9998, 0.9948, 0.9998, 0.9998, 0.9998, 0.9999, 0.9998,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4100, avg loss: 1.202396\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9998, 0.9998, 0.9873, 0.9998, 0.9999, 0.9998, 0.9998,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4200, avg loss: 1.202018\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9998, 0.9999, 0.9998, 0.9999, 0.9998, 0.9999, 0.9999, 0.9955,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4300, avg loss: 1.202557\n",
      "learning rate: 0.000009\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9998, 0.9997, 0.9998, 0.9999, 0.9999, 0.9999, 0.9958,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4400, avg loss: 1.201780\n",
      "learning rate: 0.000009\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9951, 0.9998, 0.9999, 0.9999, 0.9999,\n",
      "         0.9961]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4500, avg loss: 1.201382\n",
      "learning rate: 0.000009\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9897, 0.9999,\n",
      "         0.9955]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4600, avg loss: 1.201439\n",
      "learning rate: 0.000009\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9998, 0.9998, 0.9999, 0.9997, 0.9985, 0.9910, 0.9913, 0.9921,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9997], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4700, avg loss: 1.200606\n",
      "learning rate: 0.000009\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9932, 0.9999, 0.9999, 0.9999, 0.9900, 0.9998, 0.9997, 0.9999,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4800, avg loss: 1.200838\n",
      "learning rate: 0.000010\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9950, 0.9998, 0.9999, 0.9999, 0.9998, 0.9999, 0.9998, 0.9998,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4900, avg loss: 1.200893\n",
      "learning rate: 0.000010\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 5000, avg loss: 1.200872\n",
      "learning rate: 0.000010\n",
      "\n",
      "test similarity: [0.99993336 0.99993354 0.9999379  0.9999371  0.99993426 0.9999308\n",
      " 0.999935   0.9999338  0.99993724 0.9999333  0.9999355  0.9999326\n",
      " 0.9999357  0.9999323  0.9999363  0.99993485]\n",
      "test similarity: [0.999953   0.99995303 0.99995667 0.999956   0.99994695 0.99995875\n",
      " 0.9999541  0.9999575  0.9999609  0.9999522  0.99995875 0.9999522\n",
      " 0.99994236 0.9999586  0.999953   0.9999585 ]\n",
      "rouge-1: 0.1253554272188134, rouge-2: 0.008315738413513022, rouge-L: 0.10497691804937204\n",
      "val rouge: 0.079549\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9998, 0.9999, 0.9878, 0.9999,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 5100, avg loss: 1.199776\n",
      "learning rate: 0.000010\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9905, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 5200, avg loss: 1.207599\n",
      "learning rate: 0.000010\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9998, 0.9997, 0.9999, 0.9999, 0.9998, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 5300, avg loss: 1.201741\n",
      "learning rate: 0.000011\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9998, 0.9998, 0.9999, 0.9956, 0.9998, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 5400, avg loss: 1.201571\n",
      "learning rate: 0.000011\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 100, avg loss: 1.200766\n",
      "learning rate: 0.000011\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 200, avg loss: 1.201092\n",
      "learning rate: 0.000011\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9960, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 300, avg loss: 1.201536\n",
      "learning rate: 0.000011\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9966, 0.9998, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9878], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 400, avg loss: 1.201659\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 1.0000, 0.9947, 1.0000, 0.9999, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 500, avg loss: 1.201344\n",
      "learning rate: 0.000012\n",
      "\n",
      "test similarity: [1.0000001  0.99999994 1.         1.         1.0000001  1.0000001\n",
      " 1.         0.99999994 1.         1.         1.0000001  1.0000001\n",
      " 0.9999999  1.         0.9999999  1.0000001 ]\n",
      "test similarity: [1.         0.99999994 0.9999999  1.         1.         0.99999994\n",
      " 1.         0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 1.         1.        ]\n",
      "rouge-1: 0.10817124058593502, rouge-2: 0.0068562573966195394, rouge-L: 0.09235576985720437\n",
      "val rouge: 0.069128\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 600, avg loss: 1.200495\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9940, 0.9999, 1.0000, 1.0000, 0.9952, 0.9999, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 700, avg loss: 1.200787\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9997, 0.9999, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9933, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 800, avg loss: 1.200316\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9999, 0.9998, 0.9998, 0.9997, 0.9999, 0.9999, 0.9999, 0.9998,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 900, avg loss: 1.201017\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 0.9998, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1000, avg loss: 1.200579\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999, 0.9951, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9396], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1100, avg loss: 1.200720\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9938, 0.9938, 0.9939, 0.9937, 0.9938, 0.9951, 0.9938, 0.9938, 0.9924,\n",
      "         0.9937]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9939], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1200, avg loss: 1.200576\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9894, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9915], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1300, avg loss: 1.199916\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9995], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1400, avg loss: 1.201568\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 1.0000, 0.9999, 1.0000, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1500, avg loss: 1.201138\n",
      "learning rate: 0.000014\n",
      "\n",
      "test similarity: [0.9999998  0.9999999  0.9999999  0.99999994 0.9999999  0.9999999\n",
      " 0.9999999  0.9999999  0.9999999  0.99999994 0.9999999  0.9999999\n",
      " 0.9999999  0.9999998  0.9999999  0.9999999 ]\n",
      "test similarity: [0.99999994 1.         0.99999994 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.99999994\n",
      " 1.         0.9999999  0.99999994 1.        ]\n",
      "rouge-1: 0.10576183094241573, rouge-2: 0.007204681884830353, rouge-L: 0.0907582469507736\n",
      "val rouge: 0.067908\n",
      "id: 0\n",
      "similarity: tensor([[0.9970, 0.9971, 0.9970, 0.9968, 0.9970, 0.9963, 0.9969, 0.9969, 0.9970,\n",
      "         0.9971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9967], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1600, avg loss: 1.201410\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 0.9999, 0.9998, 0.9999, 1.0000, 0.9999, 0.9999, 1.0000,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1700, avg loss: 1.199989\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1800, avg loss: 1.201541\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 0.9999, 1.0000, 0.9964,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 1900, avg loss: 1.201025\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9999, 0.9999, 0.9999, 1.0000, 0.9999, 0.9999, 0.9962,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2000, avg loss: 1.200253\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9998, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000,\n",
      "         0.9886]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2100, avg loss: 1.201817\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9987, 0.9986, 0.9986, 0.9986, 0.9987, 0.9989, 0.9984, 0.9986, 0.9986,\n",
      "         0.9990]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9985], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2200, avg loss: 1.200427\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9873, 1.0000, 0.9999, 0.9998, 0.9889, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2300, avg loss: 1.200417\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9944, 1.0000, 1.0000, 1.0000,\n",
      "         0.9939]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9980], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2400, avg loss: 1.201199\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9963], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2500, avg loss: 1.200608\n",
      "learning rate: 0.000016\n",
      "\n",
      "test similarity: [0.99999994 0.99999994 0.9999999  0.9999999  0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.9999999  0.99999994 0.9999999  0.99999994\n",
      " 0.9999999  0.99999994 0.9999999  1.        ]\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.9999998  0.99999994 0.9999999  0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.9999999 ]\n",
      "rouge-1: 0.10619566399968926, rouge-2: 0.007058892371210565, rouge-L: 0.09158833075074875\n",
      "val rouge: 0.068281\n",
      "id: 0\n",
      "similarity: tensor([[0.9974, 1.0000, 1.0000, 0.9943, 0.9975, 0.9971, 1.0000, 1.0000, 0.9905,\n",
      "         0.9997]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2600, avg loss: 1.201999\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2700, avg loss: 1.201291\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9965,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2800, avg loss: 1.200249\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9970, 1.0000, 0.9972, 0.9968, 0.9999, 1.0000, 0.9998,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 2900, avg loss: 1.201308\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 0.9833, 1.0000, 1.0000, 1.0000, 0.9953, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3000, avg loss: 1.200446\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000, 0.9999, 0.9964, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3100, avg loss: 1.200702\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9934, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3200, avg loss: 1.200634\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3300, avg loss: 1.200834\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3400, avg loss: 1.200424\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9943, 1.0000, 0.9954, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3500, avg loss: 1.201039\n",
      "learning rate: 0.000018\n",
      "\n",
      "test similarity: [0.9999999  0.9999999  0.9999999  0.9999999  0.9999999  0.9999999\n",
      " 0.99999994 0.9999999  0.9999999  0.99999994 0.9999999  0.9999999\n",
      " 0.99999994 0.99999994 0.9999999  0.9999999 ]\n",
      "test similarity: [0.99999994 1.         0.99999994 0.99999994 1.         0.99999994\n",
      " 1.         0.9999998  1.         0.99999994 1.         1.\n",
      " 0.99999994 1.         0.99999994 0.99999994]\n",
      "rouge-1: 0.1050446318110601, rouge-2: 0.0069273012092369085, rouge-L: 0.0906140986476812\n",
      "val rouge: 0.067529\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 1.0000, 0.9927, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9969]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3600, avg loss: 1.201243\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9971], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3700, avg loss: 1.201073\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9946, 0.9946, 0.9947, 0.9869, 0.9946, 0.9943, 0.9946, 0.9947, 0.9947,\n",
      "         0.9944]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9946], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3800, avg loss: 1.200911\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 0.9997, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 3900, avg loss: 1.201128\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9979,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4000, avg loss: 1.200184\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4100, avg loss: 1.200716\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4200, avg loss: 1.200695\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 0.9667, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4300, avg loss: 1.199741\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9796, 0.9999, 0.9996, 1.0000, 0.9999, 0.9999, 1.0000,\n",
      "         0.9998]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4400, avg loss: 1.200410\n",
      "learning rate: 0.000020\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4500, avg loss: 1.201139\n",
      "learning rate: 0.000020\n",
      "\n",
      "test similarity: [0.99999994 0.9999998  0.99999994 0.9999999  0.99999994 0.9999999\n",
      " 0.99999994 0.9999998  0.9999998  0.99999994 0.99999994 0.9999998\n",
      " 0.99999994 0.9999999  0.9999998  0.9999999 ]\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.        1.        1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.        1.\n",
      " 1.0000001 1.0000001]\n",
      "rouge-1: 0.10804225181744519, rouge-2: 0.0071758032684620275, rouge-L: 0.09248367249731171\n",
      "val rouge: 0.069234\n",
      "id: 0\n",
      "similarity: tensor([[0.9948, 0.9966, 0.9964, 0.9974, 0.9966, 0.9966, 0.9962, 0.9965, 0.9965,\n",
      "         0.9965]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9894], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4600, avg loss: 1.200464\n",
      "learning rate: 0.000020\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999, 0.9970,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9972], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4700, avg loss: 1.201153\n",
      "learning rate: 0.000020\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9906, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9862]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9998], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4800, avg loss: 1.199651\n",
      "learning rate: 0.000020\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 0.9982, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 4900, avg loss: 1.200874\n",
      "learning rate: 0.000020\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9974, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9977, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 5000, avg loss: 1.200887\n",
      "learning rate: 0.000020\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9946, 0.9949, 0.9949, 0.9946, 0.9948, 0.9948, 0.9946, 0.9948, 0.9947,\n",
      "         0.9949]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9948], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 5100, avg loss: 1.200712\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9984, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 5200, avg loss: 1.202758\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 5300, avg loss: 1.200144\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9976, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 2, batch: 5400, avg loss: 1.200531\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9967, 0.9931, 0.9929, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931, 0.9931,\n",
      "         0.9931]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9931], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 100, avg loss: 1.200527\n",
      "learning rate: 0.000019\n",
      "\n",
      "test similarity: [1.0000002 1.0000001 1.0000001 1.0000001 1.0000002 1.0000001 1.0000002\n",
      " 1.0000002 1.0000001 1.0000002 1.0000002 1.0000001 1.0000002 1.0000001\n",
      " 1.0000002 1.       ]\n",
      "test similarity: [1.0000001 1.0000001 1.        1.0000001 1.0000001 1.        1.0000001\n",
      " 1.        1.0000001 1.        1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.       ]\n",
      "rouge-1: 0.10767489075951363, rouge-2: 0.007196464213991653, rouge-L: 0.09253418203635864\n",
      "val rouge: 0.069135\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 200, avg loss: 1.200730\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9973, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 300, avg loss: 1.200461\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 400, avg loss: 1.200664\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 500, avg loss: 1.200379\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9937, 0.9937, 0.9938, 0.9938, 0.9936, 0.9936, 0.9937, 0.9937, 0.9938,\n",
      "         0.9937]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9932], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 600, avg loss: 1.200542\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9972, 0.9998, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 700, avg loss: 1.200663\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9977, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9980], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 800, avg loss: 1.200290\n",
      "learning rate: 0.000019\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9973, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         0.9979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 900, avg loss: 1.200842\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9979, 0.9979, 0.9979, 0.9980, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979,\n",
      "         0.9979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9979], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1000, avg loss: 1.200737\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9957, 0.9958, 0.9959, 0.9958, 0.9958, 0.9958, 0.9961, 0.9958, 0.9961,\n",
      "         0.9958]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9958], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1100, avg loss: 1.200296\n",
      "learning rate: 0.000018\n",
      "\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.        1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "rouge-1: 0.10664834645955108, rouge-2: 0.007019394639814403, rouge-L: 0.09105898064265744\n",
      "val rouge: 0.068242\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1200, avg loss: 1.200368\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9998,\n",
      "         0.9989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9979], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1300, avg loss: 1.200636\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1400, avg loss: 1.201080\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1500, avg loss: 1.200314\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9981]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1600, avg loss: 1.200462\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9999, 0.9999, 0.9999, 1.0000, 0.9999, 0.9998, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1700, avg loss: 1.200072\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1800, avg loss: 1.200831\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9981, 0.9981, 0.9980, 0.9980,\n",
      "         0.9980]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9979], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 1900, avg loss: 1.200896\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2000, avg loss: 1.200422\n",
      "learning rate: 0.000018\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 0.9977,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2100, avg loss: 1.200459\n",
      "learning rate: 0.000018\n",
      "\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 1.         1.         0.99999994\n",
      " 0.99999994 1.         0.99999994 1.        ]\n",
      "test similarity: [0.99999994 0.99999994 0.9999999  0.99999994 0.9999999  0.9999999\n",
      " 0.9999999  0.9999999  0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.9999998  0.99999994 0.99999994 0.9999999 ]\n",
      "rouge-1: 0.10714814989710279, rouge-2: 0.007257849455707642, rouge-L: 0.09165704085087582\n",
      "val rouge: 0.068688\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 1.0000, 0.9999, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9817], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2200, avg loss: 1.199992\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9964, 1.0000, 0.9978, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2300, avg loss: 1.200268\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2400, avg loss: 1.201191\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9762, 0.9766, 0.9774, 0.9761, 0.9763, 0.9764, 0.9764, 0.9765, 0.9764,\n",
      "         0.9769]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9761], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2500, avg loss: 1.200641\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9995]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2600, avg loss: 1.200447\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9974, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2700, avg loss: 1.200385\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9968, 1.0000, 1.0000, 1.0000, 0.9894, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2800, avg loss: 1.200837\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9896, 1.0000, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 2900, avg loss: 1.200563\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9964, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9967], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3000, avg loss: 1.200504\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9966,\n",
      "         0.9967]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3100, avg loss: 1.200414\n",
      "learning rate: 0.000017\n",
      "\n",
      "test similarity: [1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002\n",
      " 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002\n",
      " 1.0000002 1.0000002]\n",
      "test similarity: [1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002\n",
      " 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002 1.0000002\n",
      " 1.0000002 1.0000002]\n",
      "rouge-1: 0.10625664866149861, rouge-2: 0.007092307998925618, rouge-L: 0.09131664417780339\n",
      "val rouge: 0.068222\n",
      "id: 0\n",
      "similarity: tensor([[0.9970, 0.9978, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979, 0.9979,\n",
      "         0.9979]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9978], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3200, avg loss: 1.200414\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9822, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3300, avg loss: 1.201018\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9987, 0.9984, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3400, avg loss: 1.200176\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3500, avg loss: 1.200186\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9963, 0.9963, 0.9964, 0.9964, 0.9964, 0.9964, 0.9964, 0.9965, 0.9965,\n",
      "         0.9964]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9964], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3600, avg loss: 1.200089\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9980, 1.0000, 1.0000, 1.0000, 1.0000, 0.9975,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3700, avg loss: 1.200786\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9980], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3800, avg loss: 1.200034\n",
      "learning rate: 0.000017\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9954, 1.0000, 0.9788, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 3900, avg loss: 1.199949\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9889, 0.9889, 0.9888, 0.9893, 0.9890, 0.9888, 0.9888, 0.9888, 0.9888,\n",
      "         0.9927]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9888], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4000, avg loss: 1.199939\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9915, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4100, avg loss: 1.200346\n",
      "learning rate: 0.000016\n",
      "\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.9999999\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "test similarity: [0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.99999976\n",
      " 0.9999998  0.99999976 0.99999976 0.9999998  0.99999976 0.9999998\n",
      " 0.9999998  0.99999976 0.9999998  0.99999976]\n",
      "rouge-1: 0.10189872915043875, rouge-2: 0.006668640958320281, rouge-L: 0.08777260975508083\n",
      "val rouge: 0.065447\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9960, 0.9971, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4200, avg loss: 1.200510\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9971], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4300, avg loss: 1.200269\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9954, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9970, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4400, avg loss: 1.200523\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9968, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9969, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4500, avg loss: 1.200278\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9923, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4600, avg loss: 1.199815\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         0.9976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9918], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4700, avg loss: 1.200855\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9981, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4800, avg loss: 1.200600\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 4900, avg loss: 1.200209\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9982, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 5000, avg loss: 1.200232\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 5100, avg loss: 1.200261\n",
      "learning rate: 0.000016\n",
      "\n",
      "test similarity: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test similarity: [1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.99999994 1.         1.         1.\n",
      " 0.99999994 1.         1.         1.        ]\n",
      "rouge-1: 0.10630971696864473, rouge-2: 0.0073271773822421345, rouge-L: 0.09138240390169593\n",
      "val rouge: 0.068340\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 1.0000, 0.9999, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9954], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 5200, avg loss: 1.199984\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9907, 0.9999, 1.0000, 0.9900, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 5300, avg loss: 1.200317\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9979, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9984, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 3, batch: 5400, avg loss: 1.200555\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9933, 0.9934, 0.9933, 0.9934, 0.9934, 0.9933, 0.9939, 0.9939, 0.9932,\n",
      "         0.9933]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9933], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 100, avg loss: 1.199982\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9976, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 200, avg loss: 1.201065\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 300, avg loss: 1.200066\n",
      "learning rate: 0.000016\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9976, 0.9999, 1.0000, 0.9946, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 400, avg loss: 1.201158\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9968, 0.9973, 0.9974, 0.9974, 0.9967, 0.9973, 0.9973, 0.9963, 0.9973,\n",
      "         0.9974]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9968], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 500, avg loss: 1.200408\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9987, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 600, avg loss: 1.200510\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9976, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 700, avg loss: 1.200403\n",
      "learning rate: 0.000015\n",
      "\n",
      "test similarity: [0.99999994 0.99999994 0.9999999  0.9999999  0.99999994 0.99999994\n",
      " 0.9999999  0.99999994 0.99999994 0.99999994 0.99999994 0.9999999\n",
      " 0.99999994 0.99999994 0.99999994 0.9999999 ]\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.9999999  0.9999999  0.9999999  0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "rouge-1: 0.10619424660617179, rouge-2: 0.007090190514204118, rouge-L: 0.09113513521143789\n",
      "val rouge: 0.068140\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9959, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 800, avg loss: 1.200416\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9971, 0.9972, 0.9972, 0.9972, 0.9972, 0.9971, 0.9972, 0.9971, 0.9975,\n",
      "         0.9972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9971], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 900, avg loss: 1.200194\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9990, 0.9986, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1000, avg loss: 1.200344\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9982, 1.0000,\n",
      "         0.9986]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1100, avg loss: 1.200212\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9979, 0.9979, 0.9982, 0.9980, 0.9981, 0.9980, 0.9980, 0.9980, 0.9980,\n",
      "         0.9985]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9980], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1200, avg loss: 1.200080\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9972, 0.9972, 0.9971, 0.9972, 0.9973, 0.9972, 0.9972, 0.9971, 0.9968,\n",
      "         0.9951]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9972], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1300, avg loss: 1.200381\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9986]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1400, avg loss: 1.200432\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9937, 0.9999, 0.9864, 0.9941, 0.9999, 0.9944, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1500, avg loss: 1.200224\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9985, 0.9986, 0.9985, 0.9980, 0.9980, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9979], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1600, avg loss: 1.200416\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1700, avg loss: 1.200073\n",
      "learning rate: 0.000015\n",
      "\n",
      "test similarity: [0.99999976 0.99999976 0.99999976 0.99999976 0.99999976 0.99999976\n",
      " 0.99999976 0.99999976 0.99999976 0.99999976 0.99999976 0.99999976\n",
      " 0.99999976 0.99999976 0.99999976 0.99999976]\n",
      "test similarity: [0.99999976 0.99999976 0.99999976 0.99999976 0.99999976 0.99999976\n",
      " 0.99999976 0.99999976 0.99999976 0.99999976 0.99999976 0.99999976\n",
      " 0.9999999  0.99999976 0.99999976 0.99999976]\n",
      "rouge-1: 0.09846690298197412, rouge-2: 0.006386608197437862, rouge-L: 0.08580132173879253\n",
      "val rouge: 0.063552\n",
      "id: 0\n",
      "similarity: tensor([[0.9981, 0.9980, 0.9980, 0.9980, 0.9980, 0.9981, 0.9979, 0.9980, 0.9980,\n",
      "         0.9980]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9979], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1800, avg loss: 1.200338\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9974, 1.0000, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 1900, avg loss: 1.200198\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2000, avg loss: 1.200337\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9984, 0.9982, 0.9988, 1.0000, 1.0000, 0.9982, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9976], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2100, avg loss: 1.200308\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2200, avg loss: 1.200218\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9964, 0.9976, 0.9975, 1.0000, 0.9999, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2300, avg loss: 1.200276\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9981, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2400, avg loss: 1.200191\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9975, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2500, avg loss: 1.200473\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9967, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2600, avg loss: 1.199486\n",
      "learning rate: 0.000015\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2700, avg loss: 1.200313\n",
      "learning rate: 0.000015\n",
      "\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "rouge-1: 0.10585051370302019, rouge-2: 0.007263417688460892, rouge-L: 0.09101237284424801\n",
      "val rouge: 0.068042\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 0.9999,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2800, avg loss: 1.200118\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9975, 0.9973, 0.9975, 0.9975, 0.9973, 0.9975, 0.9976, 0.9975, 0.9975,\n",
      "         0.9975]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9975], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 2900, avg loss: 1.200517\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3000, avg loss: 1.200191\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9997,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3100, avg loss: 1.200092\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9977, 1.0000, 0.9999, 1.0000, 1.0000, 0.9958,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3200, avg loss: 1.200251\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9982, 0.9989, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3300, avg loss: 1.200341\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9981, 1.0000, 1.0000,\n",
      "         0.9981]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3400, avg loss: 1.200230\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 1.0000, 0.9999, 1.0000, 0.9999, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3500, avg loss: 1.200521\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9918, 0.9919, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3600, avg loss: 1.199977\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9958, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3700, avg loss: 1.200453\n",
      "learning rate: 0.000014\n",
      "\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "rouge-1: 0.10597506922145691, rouge-2: 0.0072845459150197725, rouge-L: 0.09113246267540871\n",
      "val rouge: 0.068131\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9997, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3800, avg loss: 1.200234\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9981, 0.9978, 0.9978, 0.9978, 0.9978, 0.9978, 0.9977, 0.9978, 0.9978,\n",
      "         0.9978]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9978], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 3900, avg loss: 1.200269\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4000, avg loss: 1.200295\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4100, avg loss: 1.200099\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4200, avg loss: 1.200769\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9981, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4300, avg loss: 1.200702\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9982, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4400, avg loss: 1.200207\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9988, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4500, avg loss: 1.200309\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4600, avg loss: 1.200214\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4700, avg loss: 1.200410\n",
      "learning rate: 0.000014\n",
      "\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "test similarity: [1.0000001 1.0000001 1.0000002 1.0000001 1.0000001 1.0000002 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000002 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000002]\n",
      "rouge-1: 0.10591825826123819, rouge-2: 0.007297385878838459, rouge-L: 0.09105767553919242\n",
      "val rouge: 0.068091\n",
      "id: 0\n",
      "similarity: tensor([[0.9984, 0.9984, 0.9984, 0.9984, 0.9983, 0.9983, 0.9984, 0.9983, 0.9984,\n",
      "         0.9981]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9984], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4800, avg loss: 1.200204\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9971, 0.9971, 0.9971, 0.9971, 0.9967, 0.9971, 0.9971, 0.9971, 0.9971,\n",
      "         0.9971]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9971], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 4900, avg loss: 1.200172\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9972]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 5000, avg loss: 1.200182\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9979, 0.9975,\n",
      "         0.9983]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 5100, avg loss: 1.200229\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 5200, avg loss: 1.200270\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 5300, avg loss: 1.200458\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9980, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9987,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 4, batch: 5400, avg loss: 1.200114\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9998, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 100, avg loss: 1.200371\n",
      "learning rate: 0.000014\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9987, 0.9987, 0.9988, 0.9987, 0.9987, 0.9985, 0.9988, 0.9987, 0.9984,\n",
      "         0.9988]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9988], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 200, avg loss: 1.200298\n",
      "learning rate: 0.000014\n",
      "\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "rouge-1: 0.10879206184250241, rouge-2: 0.0074136935297892635, rouge-L: 0.0929476746293516\n",
      "val rouge: 0.069718\n",
      "id: 0\n",
      "similarity: tensor([[0.9985, 0.9984, 0.9985, 0.9985, 0.9985, 0.9985, 0.9984, 0.9985, 0.9984,\n",
      "         0.9977]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9985], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 300, avg loss: 1.200197\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9980, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 400, avg loss: 1.200311\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 500, avg loss: 1.200291\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9989, 1.0000, 1.0000, 1.0000, 0.9985,\n",
      "         0.9992]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 600, avg loss: 1.200241\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 700, avg loss: 1.200135\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 0.9969,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 800, avg loss: 1.200311\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9965], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 900, avg loss: 1.200319\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9974,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9976], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1000, avg loss: 1.200819\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1100, avg loss: 1.200361\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9975, 1.0000, 1.0000, 1.0000, 0.9973, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1200, avg loss: 1.200095\n",
      "learning rate: 0.000013\n",
      "\n",
      "test similarity: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "test similarity: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "rouge-1: 0.10543172791701656, rouge-2: 0.007277951428186637, rouge-L: 0.09068112427420827\n",
      "val rouge: 0.067797\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 1.0000, 1.0000, 0.9974, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1300, avg loss: 1.200034\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9850, 0.9997, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1400, avg loss: 1.199417\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9999, 0.9920,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1500, avg loss: 1.200357\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1600, avg loss: 1.200561\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9985, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1700, avg loss: 1.200228\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9985, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9987], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1800, avg loss: 1.200160\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9989, 0.9989, 0.9990, 0.9985, 0.9989, 0.9990, 0.9989, 0.9989, 0.9989,\n",
      "         0.9989]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9990], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 1900, avg loss: 1.200221\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9969, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9986,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2000, avg loss: 1.200142\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 0.9979, 1.0000, 1.0000, 0.9999, 0.9988, 1.0000, 1.0000, 1.0000,\n",
      "         0.9987]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2100, avg loss: 1.200281\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9982, 0.9984, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2200, avg loss: 1.200296\n",
      "learning rate: 0.000013\n",
      "\n",
      "test similarity: [0.99999994 0.9999998  0.99999994 0.99999994 0.9999998  0.99999994\n",
      " 0.9999998  0.99999994 0.99999994 0.9999998  0.9999998  0.9999998\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "test similarity: [0.99999994 0.99999994 0.9999998  0.9999998  0.9999998  0.99999994\n",
      " 0.9999998  0.99999994 0.9999998  0.99999994 0.99999994 0.9999998\n",
      " 0.9999998  0.99999994 0.99999994 0.99999994]\n",
      "rouge-1: 0.1073155874749732, rouge-2: 0.007279724611730711, rouge-L: 0.09242988774994963\n",
      "val rouge: 0.069008\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9980, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2300, avg loss: 1.200272\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9952, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2400, avg loss: 1.200139\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2500, avg loss: 1.200281\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2600, avg loss: 1.200480\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9989, 1.0000, 1.0000, 0.9991, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2700, avg loss: 1.200266\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2800, avg loss: 1.200091\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 2900, avg loss: 1.200320\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9997, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3000, avg loss: 1.199958\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9986, 0.9985, 0.9985, 0.9986, 0.9986, 0.9986, 0.9985, 0.9986, 0.9987,\n",
      "         0.9976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9985], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3100, avg loss: 1.200606\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3200, avg loss: 1.200176\n",
      "learning rate: 0.000013\n",
      "\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "test similarity: [1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000001]\n",
      "rouge-1: 0.10597506922145691, rouge-2: 0.0072845459150197725, rouge-L: 0.09113246267540871\n",
      "val rouge: 0.068131\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9994, 1.0000, 1.0000, 0.9999, 0.9999, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3300, avg loss: 1.200151\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9987, 0.9990, 0.9987, 0.9980,\n",
      "         0.9986]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9987], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3400, avg loss: 1.200184\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3500, avg loss: 1.200196\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9999, 1.0000, 0.9985, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9999]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3600, avg loss: 1.200132\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 0.9986, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9976]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3700, avg loss: 1.200261\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3800, avg loss: 1.200253\n",
      "learning rate: 0.000013\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9980]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 3900, avg loss: 1.200075\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9987]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4000, avg loss: 1.200220\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4100, avg loss: 1.199963\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9976, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9971], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4200, avg loss: 1.200639\n",
      "learning rate: 0.000012\n",
      "\n",
      "test similarity: [1.0000001 1.        1.0000001 1.        1.0000001 1.0000001 1.\n",
      " 1.        1.        1.        1.0000001 1.0000001 1.        1.\n",
      " 1.        1.0000001]\n",
      "test similarity: [1.0000001 1.0000002 1.0000001 1.0000002 1.0000001 1.0000001 1.0000001\n",
      " 1.0000002 1.0000001 1.0000002 1.0000002 1.0000001 1.0000001 1.0000001\n",
      " 1.0000001 1.0000002]\n",
      "rouge-1: 0.10997377468823205, rouge-2: 0.0074793656728476664, rouge-L: 0.0936502899994084\n",
      "val rouge: 0.070368\n",
      "id: 0\n",
      "similarity: tensor([[0.9995, 0.9995, 0.9995, 0.9995, 0.9995, 0.9995, 0.9995, 0.9995, 0.9995,\n",
      "         0.9995]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9995], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4300, avg loss: 1.200282\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9990, 1.0000, 1.0000, 0.9987, 1.0000, 1.0000, 1.0000, 1.0000, 0.9986,\n",
      "         0.9988]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4400, avg loss: 1.200112\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 0.9985, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4500, avg loss: 1.200242\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9965, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4600, avg loss: 1.200267\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9999], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4700, avg loss: 1.200192\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4800, avg loss: 1.200031\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 4900, avg loss: 1.200520\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.9958]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 5000, avg loss: 1.200150\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 0.9979, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 5100, avg loss: 1.200027\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9983, 1.0000, 1.0000, 0.9990, 1.0000, 1.0000, 0.9986, 1.0000, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9989], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 5200, avg loss: 1.200245\n",
      "learning rate: 0.000012\n",
      "\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "test similarity: [0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994 0.99999994\n",
      " 0.99999994 0.99999994 0.99999994 0.99999994]\n",
      "rouge-1: 0.10597506922145691, rouge-2: 0.0072845459150197725, rouge-L: 0.09113246267540871\n",
      "val rouge: 0.068131\n",
      "id: 0\n",
      "similarity: tensor([[1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9978, 0.9976, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 5300, avg loss: 1.199513\n",
      "learning rate: 0.000012\n",
      "\n",
      "id: 0\n",
      "similarity: tensor([[0.9977, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 0.9977, 1.0000,\n",
      "         1.0000]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([1.0000], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 5, batch: 5400, avg loss: 1.200150\n",
      "learning rate: 0.000012\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python main.py --cuda --gpuid 0 -l --dataset {training_data_path} --model_type 'xlm-roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5d3b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████| 52.0/52.0 [00:00<00:00, 52.8kB/s]\n",
      "Downloading: 100%|██████████████████████████████| 474/474 [00:00<00:00, 453kB/s]\n",
      "Downloading: 100%|███████████████████████████| 899k/899k [00:00<00:00, 5.71MB/s]\n",
      "Downloading: 100%|███████████████████████████| 456k/456k [00:00<00:00, 3.96MB/s]\n",
      "Downloading: 100%|███████████████████████████| 559M/559M [00:07<00:00, 73.2MB/s]\n",
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Namespace(accumulate_step=12, batch_size=1, cand_weight=1, cuda=True, dataset='candidates/tuned_t5_model_16_processed', datatype='diverse', encode_mode=None, epoch=5, evaluate=False, gold_margin=0, gold_weight=1, gpuid=[0], grad_norm=0, log=True, margin=0.01, max_len=120, max_lr=0.002, max_num=16, model_pt='', model_type='microsoft/deberta-base', no_gold=False, port=12355, pretrained=None, report_freq=100, scale=1, seed=970903, warmup_steps=10000)\n",
      "\n",
      "ReRanker(\n",
      "  (encoder): DebertaModel(\n",
      "    (embeddings): DebertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
      "      (LayerNorm): DebertaLayerNorm()\n",
      "      (dropout): StableDropout()\n",
      "    )\n",
      "    (encoder): DebertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (1): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (2): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (3): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (4): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (5): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (6): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (7): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (8): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (9): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (10): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "        (11): DebertaLayer(\n",
      "          (attention): DebertaAttention(\n",
      "            (self): DisentangledSelfAttention(\n",
      "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
      "              (pos_dropout): StableDropout()\n",
      "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
      "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "            (output): DebertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): DebertaLayerNorm()\n",
      "              (dropout): StableDropout()\n",
      "            )\n",
      "          )\n",
      "          (intermediate): DebertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): DebertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): DebertaLayerNorm()\n",
      "            (dropout): StableDropout()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (rel_embeddings): Embedding(1024, 768)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.9992, 0.9948, 0.9538, 0.9974, 0.9517, 0.9974, 0.8198, 0.8197, 0.7619,\n",
      "         0.9997]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9994], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 100, avg loss: 1.675748\n",
      "learning rate: 0.000000\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.9929, 0.9979, 0.9996, 0.8175, 0.8197, 0.8196, 0.9924, 0.9995, 0.9997,\n",
      "         0.9973]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1676], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 200, avg loss: 1.712274\n",
      "learning rate: 0.000000\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.9978, 0.9987, 0.9981, 0.9524, 0.9987, 0.9537, 0.9973, 0.7623, 0.9995,\n",
      "         0.9994]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9993], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 300, avg loss: 1.679160\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.4857, 0.8026, 0.8054, 0.8058, 0.9827, 0.8132, 0.7303, 0.8043, 0.5940,\n",
      "         0.8090]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.8040], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 400, avg loss: 1.661690\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.0328, 0.0465, 0.0637, 0.0516, 0.0617, 0.0445, 0.0364, 0.0299, 0.0320,\n",
      "         0.0359]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.0479], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 500, avg loss: 1.472368\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.0559, 0.0637, 0.0591, 0.1892, 0.1332, 0.0878, 0.0613, 0.1493, 0.1152,\n",
      "         0.0743]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1366], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 600, avg loss: 1.244577\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1499, 0.0630, 0.0505, 0.0633, 0.0655, 0.0696, 0.0549, 0.1300, 0.1213,\n",
      "         0.0547]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.0709], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 700, avg loss: 1.228143\n",
      "learning rate: 0.000001\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.0699, 0.0570, 0.0690, 0.1187, 0.0713, 0.0936, 0.0672, 0.0651, 0.1365,\n",
      "         0.0539]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.0824], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 800, avg loss: 1.222073\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.0709, 0.1004, 0.1097, 0.1021, 0.1079, 0.1399, 0.1144, 0.0845, 0.1219,\n",
      "         0.1038]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1240], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 900, avg loss: 1.208092\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.0872, 0.0988, 0.1005, 0.0867, 0.0941, 0.1035, 0.0962, 0.0957, 0.0985,\n",
      "         0.0937]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1081], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1000, avg loss: 1.202054\n",
      "learning rate: 0.000002\n",
      "\n",
      "test similarity: [0.15244609 0.13003081 0.10116299 0.09573194 0.13244668 0.05449717\n",
      " 0.06571165 0.14347267 0.13067639 0.05473366 0.07542124 0.14096445\n",
      " 0.1334661  0.05705321 0.12398441 0.07079333]\n",
      "test similarity: [0.09548522 0.08911979 0.05928604 0.06170858 0.08235067 0.05429437\n",
      " 0.05407536 0.09408656 0.06494168 0.09130905 0.08464464 0.10976765\n",
      " 0.08966586 0.08133999 0.09548522 0.08347881]\n",
      "rouge-1: 0.12343220660835245, rouge-2: 0.009494422637894568, rouge-L: 0.10565116186849775\n",
      "best - epoch: 0, batch: 999\n",
      "val rouge: 0.079526\n",
      "id: 1\n",
      "similarity: tensor([[0.0738, 0.0973, 0.1170, 0.0864, 0.0849, 0.1011, 0.1119, 0.0721, 0.0912,\n",
      "         0.0856]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1193], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1100, avg loss: 1.192666\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.0805, 0.1087, 0.1283, 0.1642, 0.0986, 0.0817, 0.0901, 0.1171, 0.0778,\n",
      "         0.1001]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1213], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1200, avg loss: 1.169287\n",
      "learning rate: 0.000002\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1703, 0.1491, 0.1606, 0.1656, 0.1315, 0.1455, 0.1551, 0.1421, 0.1499,\n",
      "         0.1067]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1322], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1300, avg loss: 1.174112\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1595, 0.1447, 0.0911, 0.1091, 0.1639, 0.1574, 0.1167, 0.1194, 0.1090,\n",
      "         0.1351]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1133], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1400, avg loss: 1.177117\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1983, 0.1687, 0.1821, 0.2365, 0.1542, 0.1755, 0.1349, 0.1142, 0.1027,\n",
      "         0.1750]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1848], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1500, avg loss: 1.173555\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1789, 0.2596, 0.1830, 0.2730, 0.1316, 0.2536, 0.1711, 0.2811, 0.1586,\n",
      "         0.2049]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2862], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1600, avg loss: 1.154215\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1820, 0.1758, 0.1981, 0.2024, 0.1601, 0.1606, 0.1585, 0.1515, 0.1201,\n",
      "         0.1421]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1772], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1700, avg loss: 1.145316\n",
      "learning rate: 0.000003\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2153, 0.2140, 0.2197, 0.2394, 0.2291, 0.1864, 0.2177, 0.1381, 0.2410,\n",
      "         0.1563]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1805], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1800, avg loss: 1.153451\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2068, 0.1619, 0.1481, 0.1599, 0.2180, 0.1980, 0.1430, 0.2161, 0.1309,\n",
      "         0.2120]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1839], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 1900, avg loss: 1.137980\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2344, 0.1987, 0.2160, 0.2282, 0.1621, 0.1441, 0.1685, 0.1476, 0.1621,\n",
      "         0.2242]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1726], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2000, avg loss: 1.131404\n",
      "learning rate: 0.000004\n",
      "\n",
      "test similarity: [0.2900157  0.29218084 0.25323504 0.25281185 0.2962293  0.15129097\n",
      " 0.16463447 0.28396538 0.28759375 0.13981253 0.21475345 0.2823356\n",
      " 0.27068466 0.1378282  0.2901846  0.18875828]\n",
      "test similarity: [0.20780115 0.21409597 0.16749167 0.18652122 0.18458164 0.14400785\n",
      " 0.14836992 0.22817981 0.20669621 0.2473455  0.19222556 0.25493026\n",
      " 0.18884103 0.21131504 0.20780115 0.19074622]\n",
      "rouge-1: 0.11916738337032379, rouge-2: 0.009031605437078398, rouge-L: 0.10281076928063605\n",
      "val rouge: 0.077003\n",
      "id: 1\n",
      "similarity: tensor([[0.2127, 0.2209, 0.2335, 0.2579, 0.2159, 0.2665, 0.2348, 0.2106, 0.2681,\n",
      "         0.2109]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2365], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2100, avg loss: 1.120071\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1787, 0.2419, 0.1784, 0.1672, 0.1739, 0.2184, 0.2008, 0.2018, 0.1618,\n",
      "         0.2477]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1588], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2200, avg loss: 1.120553\n",
      "learning rate: 0.000004\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.9967, 0.9982, 0.8190, 0.9976, 0.9942, 0.9520, 0.9506, 0.9944, 0.6554,\n",
      "         0.9949]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.9936], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2300, avg loss: 1.131292\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1773, 0.2009, 0.1609, 0.1885, 0.1765, 0.1748, 0.2011, 0.1988, 0.1923,\n",
      "         0.1996]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1658], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2400, avg loss: 1.104850\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.3362, 0.2438, 0.2003, 0.2666, 0.2666, 0.3004, 0.2294, 0.2827, 0.2397,\n",
      "         0.2595]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2943], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2500, avg loss: 1.119913\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2259, 0.2367, 0.2550, 0.2522, 0.2015, 0.2438, 0.2010, 0.2609, 0.2168,\n",
      "         0.2516]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2367], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2600, avg loss: 1.130239\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2297, 0.2634, 0.2321, 0.2108, 0.1436, 0.2436, 0.1503, 0.2565, 0.2359,\n",
      "         0.2211]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2341], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2700, avg loss: 1.133781\n",
      "learning rate: 0.000005\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.3312, 0.1938, 0.3659, 0.3393, 0.2261, 0.3340, 0.3481, 0.3735, 0.2853,\n",
      "         0.3474]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.3196], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2800, avg loss: 1.112177\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.3454, 0.3677, 0.3524, 0.3258, 0.3091, 0.2155, 0.3282, 0.3536, 0.3364,\n",
      "         0.2420]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.3670], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 2900, avg loss: 1.116069\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.6021, 0.6764, 0.6860, 0.6000, 0.6135, 0.6165, 0.6180, 0.6368, 0.4163,\n",
      "         0.5846]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.6683], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3000, avg loss: 1.092064\n",
      "learning rate: 0.000006\n",
      "\n",
      "test similarity: [0.3126912  0.29756743 0.2674641  0.24822018 0.29562557 0.16168746\n",
      " 0.1869469  0.30324253 0.29010737 0.1545233  0.24145347 0.30537605\n",
      " 0.28671652 0.1539728  0.29178748 0.20103565]\n",
      "test similarity: [0.23413187 0.2117169  0.19259301 0.19095357 0.20868415 0.16477653\n",
      " 0.17929912 0.21682692 0.20334336 0.26548576 0.19064176 0.27302557\n",
      " 0.17523476 0.223655   0.23413187 0.18363251]\n",
      "rouge-1: 0.11790815865949611, rouge-2: 0.0084262798773427, rouge-L: 0.1015308502849631\n",
      "val rouge: 0.075955\n",
      "id: 1\n",
      "similarity: tensor([[0.3160, 0.3058, 0.2760, 0.3625, 0.3272, 0.2248, 0.3251, 0.2779, 0.3399,\n",
      "         0.2369]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.3327], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3100, avg loss: 1.108279\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2527, 0.2911, 0.2813, 0.2118, 0.1868, 0.1961, 0.2142, 0.1824, 0.2259,\n",
      "         0.1916]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2687], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3200, avg loss: 1.123298\n",
      "learning rate: 0.000006\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.3159, 0.3351, 0.3242, 0.3292, 0.2785, 0.2424, 0.2155, 0.2736, 0.2741,\n",
      "         0.2862]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.3287], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3300, avg loss: 1.104236\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2494, 0.2040, 0.1938, 0.2116, 0.2152, 0.2142, 0.2163, 0.2195, 0.2233,\n",
      "         0.2179]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2833], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3400, avg loss: 1.105956\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2719, 0.2625, 0.2891, 0.2424, 0.2722, 0.2472, 0.2523, 0.2644, 0.2581,\n",
      "         0.2568]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.3111], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3500, avg loss: 1.097683\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2182, 0.2355, 0.1911, 0.1829, 0.2107, 0.1922, 0.2663, 0.2796, 0.2015,\n",
      "         0.2664]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2062], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3600, avg loss: 1.099948\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1428, 0.1881, 0.1987, 0.2207, 0.1696, 0.1915, 0.1885, 0.1818, 0.1320,\n",
      "         0.1243]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1860], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3700, avg loss: 1.080058\n",
      "learning rate: 0.000007\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2137, 0.2146, 0.1627, 0.2144, 0.2181, 0.2234, 0.1381, 0.2098, 0.2117,\n",
      "         0.1642]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2759], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3800, avg loss: 1.109845\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2831, 0.2558, 0.2244, 0.2470, 0.2914, 0.3226, 0.3021, 0.2690, 0.3016,\n",
      "         0.2511]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2953], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 3900, avg loss: 1.079692\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.3085, 0.3167, 0.2883, 0.2750, 0.3039, 0.2702, 0.2857, 0.3142, 0.2765,\n",
      "         0.2873]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2376], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4000, avg loss: 1.084546\n",
      "learning rate: 0.000008\n",
      "\n",
      "test similarity: [0.33314997 0.3233649  0.286767   0.26457083 0.3120599  0.17941426\n",
      " 0.2077291  0.3295741  0.28120363 0.1854602  0.24314758 0.31288773\n",
      " 0.28780043 0.17025612 0.299821   0.19399136]\n",
      "test similarity: [0.24069095 0.22180365 0.21440752 0.19914229 0.2365423  0.1929506\n",
      " 0.2107386  0.24516672 0.23070753 0.28285402 0.2160709  0.2622981\n",
      " 0.17659235 0.2563287  0.24069095 0.20567457]\n",
      "rouge-1: 0.11753449905882032, rouge-2: 0.008445747319109218, rouge-L: 0.10057152769470501\n",
      "val rouge: 0.075517\n",
      "id: 1\n",
      "similarity: tensor([[0.2218, 0.2672, 0.1470, 0.3034, 0.2810, 0.1946, 0.2647, 0.1807, 0.2384,\n",
      "         0.2734]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2051], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4100, avg loss: 1.097445\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.2519, 0.2513, 0.2437, 0.2404, 0.2473, 0.2272, 0.2352, 0.2515, 0.2436,\n",
      "         0.2021]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.2620], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4200, avg loss: 1.080973\n",
      "learning rate: 0.000008\n",
      "\n",
      "id: 1\n",
      "similarity: tensor([[0.1924, 0.1808, 0.1508, 0.1368, 0.1416, 0.1455, 0.2012, 0.1813, 0.2312,\n",
      "         0.1532]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "gold similarity: tensor([0.1954], device='cuda:0', grad_fn=<SumBackward1>)\n",
      "epoch: 1, batch: 4300, avg loss: 1.094303\n",
      "learning rate: 0.000009\n",
      "\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 291, in <module>\n",
      "    main(args)\n",
      "  File \"main.py\", line 266, in main\n",
      "    run(0, args)\n",
      "  File \"main.py\", line 216, in run\n",
      "    loss = args.scale * RankingLoss(similarity, gold_similarity, args.margin, args.gold_margin, args.gold_weight)\n",
      "  File \"/home/azathoth/SimCLS/model.py\", line 21, in RankingLoss\n",
      "    loss = loss_func(pos_score, neg_score, ones)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\", line 1323, in forward\n",
      "    return F.margin_ranking_loss(input1, input2, target, margin=self.margin, reduction=self.reduction)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\", line 3319, in margin_ranking_loss\n",
      "    return torch.margin_ranking_loss(input1, input2, target, margin, reduction_enum)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py --cuda --gpuid 0 -l --dataset {training_data_path} --model_type 'microsoft/deberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1812d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --cuda --gpuid 0 -l --dataset {training_data_path} --model_type 'google/electra-small-discriminator'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793471f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --cuda --gpuid 0 -l --dataset {training_data_path} --model_type 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48f108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39562edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training scorer\n",
    "training_data_path = f'candidates/{args.generator_name}_{args.num_cands}_processed'\n",
    "!python main.py --cuda --gpuid 0 -l --dataset {training_data_path}\n",
    "# default training for 5 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d48cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start tokenize data\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  2.82ba/s]\n",
      "There are 814 samples in test set!\n",
      "start loading scorer model\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "start evaluating, total_num of samples is:814\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "current working sample: 814, time used last sample: 0.8097\n",
      "Before SimCLS ROUGE1: 0.4266898826000848, ROUGE2: 0.2222665339329595, ROUGEL: 0.36588897555246697\n",
      "After SimCLS ROUGE1: 0.4124686207404652, ROUGE2: 0.20060312960241553, ROUGEL: 0.3469416141693205\n"
     ]
    }
   ],
   "source": [
    "# start evaluating scorer just trained\n",
    "!python evaluate_model.py --generator_name {args.generator_name} --dataset_name {args.dataset_name} --scorer_path 'cache/22-12-17-0-xlm-roberta-base/scorer.bin' --dataset_percent 1 --scorer_architecture_name 'xlm-roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbefbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
