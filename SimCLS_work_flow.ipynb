{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b8596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afd16ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 16:05:42.041874: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import datasets\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    AutoModel\n",
    ")\n",
    "\n",
    "from tabulate import tabulate\n",
    "import nltk\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd29cfd",
   "metadata": {},
   "source": [
    "# 1,load model, tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf987ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/wmbw_rv57_g2jq_w3v99jyrr0000gn/T/ipykernel_52413/1189849771.py:2: DtypeWarning: Columns (1,4,5,6,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('clean_covid.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('clean_covid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c3cb27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>objective this retrospective chart review desc...</td>\n",
       "      <td>clinical features of culture proven mycoplasma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>nitric oxide a pro inflammatory mediator in lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surfactant protein d sp d participates in the ...</td>\n",
       "      <td>surfactant protein d and pulmonary host defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>endothelin et is a amino acid peptide with div...</td>\n",
       "      <td>role of endothelin in lung disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>respiratory syncytial virus rsv and pneumonia ...</td>\n",
       "      <td>gene expression in epithelial cells in respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814829</th>\n",
       "      <td>ncov which is a novel coronavirus emerged in ...</td>\n",
       "      <td>potent neutralization of novel coronavirus by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814830</th>\n",
       "      <td>microbiology laboratories have traditionally r...</td>\n",
       "      <td>molecular based diagnostics including future t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814831</th>\n",
       "      <td>to present a patient with bilateral conjunctiv...</td>\n",
       "      <td>a patient with bilateral conjunctivitis positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814832</th>\n",
       "      <td>given covid pandemic periodic outpatient asses...</td>\n",
       "      <td>incidental lowering of otitis media complaints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814833</th>\n",
       "      <td>objective to examine interhospital variation i...</td>\n",
       "      <td>hospital variation in admissions to neonatal i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814833 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract  \\\n",
       "0       objective this retrospective chart review desc...   \n",
       "1       inflammatory diseases of the respiratory tract...   \n",
       "2       surfactant protein d sp d participates in the ...   \n",
       "3       endothelin et is a amino acid peptide with div...   \n",
       "4       respiratory syncytial virus rsv and pneumonia ...   \n",
       "...                                                   ...   \n",
       "814829   ncov which is a novel coronavirus emerged in ...   \n",
       "814830  microbiology laboratories have traditionally r...   \n",
       "814831  to present a patient with bilateral conjunctiv...   \n",
       "814832  given covid pandemic periodic outpatient asses...   \n",
       "814833  objective to examine interhospital variation i...   \n",
       "\n",
       "                                                    title  \n",
       "0       clinical features of culture proven mycoplasma...  \n",
       "1       nitric oxide a pro inflammatory mediator in lu...  \n",
       "2         surfactant protein d and pulmonary host defense  \n",
       "3                      role of endothelin in lung disease  \n",
       "4       gene expression in epithelial cells in respons...  \n",
       "...                                                   ...  \n",
       "814829  potent neutralization of novel coronavirus by ...  \n",
       "814830  molecular based diagnostics including future t...  \n",
       "814831  a patient with bilateral conjunctivitis positi...  \n",
       "814832  incidental lowering of otitis media complaints...  \n",
       "814833  hospital variation in admissions to neonatal i...  \n",
       "\n",
       "[814833 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['abstract','title']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3deaeab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>objective this retrospective chart review desc...</td>\n",
       "      <td>clinical features of culture proven mycoplasma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>nitric oxide a pro inflammatory mediator in lu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>surfactant protein d sp d participates in the ...</td>\n",
       "      <td>surfactant protein d and pulmonary host defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>endothelin et is a amino acid peptide with div...</td>\n",
       "      <td>role of endothelin in lung disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>respiratory syncytial virus rsv and pneumonia ...</td>\n",
       "      <td>gene expression in epithelial cells in respons...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814829</th>\n",
       "      <td>ncov which is a novel coronavirus emerged in ...</td>\n",
       "      <td>potent neutralization of novel coronavirus by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814830</th>\n",
       "      <td>microbiology laboratories have traditionally r...</td>\n",
       "      <td>molecular based diagnostics including future t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814831</th>\n",
       "      <td>to present a patient with bilateral conjunctiv...</td>\n",
       "      <td>a patient with bilateral conjunctivitis positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814832</th>\n",
       "      <td>given covid pandemic periodic outpatient asses...</td>\n",
       "      <td>incidental lowering of otitis media complaints...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814833</th>\n",
       "      <td>objective to examine interhospital variation i...</td>\n",
       "      <td>hospital variation in admissions to neonatal i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814834 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 abstract  \\\n",
       "0       objective this retrospective chart review desc...   \n",
       "1       inflammatory diseases of the respiratory tract...   \n",
       "2       surfactant protein d sp d participates in the ...   \n",
       "3       endothelin et is a amino acid peptide with div...   \n",
       "4       respiratory syncytial virus rsv and pneumonia ...   \n",
       "...                                                   ...   \n",
       "814829   ncov which is a novel coronavirus emerged in ...   \n",
       "814830  microbiology laboratories have traditionally r...   \n",
       "814831  to present a patient with bilateral conjunctiv...   \n",
       "814832  given covid pandemic periodic outpatient asses...   \n",
       "814833  objective to examine interhospital variation i...   \n",
       "\n",
       "                                                    title  \n",
       "0       clinical features of culture proven mycoplasma...  \n",
       "1       nitric oxide a pro inflammatory mediator in lu...  \n",
       "2         surfactant protein d and pulmonary host defense  \n",
       "3                      role of endothelin in lung disease  \n",
       "4       gene expression in epithelial cells in respons...  \n",
       "...                                                   ...  \n",
       "814829  potent neutralization of novel coronavirus by ...  \n",
       "814830  molecular based diagnostics including future t...  \n",
       "814831  a patient with bilateral conjunctivitis positi...  \n",
       "814832  incidental lowering of otitis media complaints...  \n",
       "814833  hospital variation in admissions to neonatal i...  \n",
       "\n",
       "[814834 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['abstract','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2907f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         objective this retrospective chart review desc...\n",
       "1         inflammatory diseases of the respiratory tract...\n",
       "2         surfactant protein d sp d participates in the ...\n",
       "3         endothelin et is a amino acid peptide with div...\n",
       "4         respiratory syncytial virus rsv and pneumonia ...\n",
       "                                ...                        \n",
       "814829     ncov which is a novel coronavirus emerged in ...\n",
       "814830    microbiology laboratories have traditionally r...\n",
       "814831    to present a patient with bilateral conjunctiv...\n",
       "814832    given covid pandemic periodic outpatient asses...\n",
       "814833    objective to examine interhospital variation i...\n",
       "Name: abstract, Length: 814834, dtype: string"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['abstract'].astype('string')\n",
    "data['abstract'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dcf0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['abstract'] = data['abstract'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40056a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         objective this retrospective chart review desc...\n",
       "1         inflammatory diseases of the respiratory tract...\n",
       "2         surfactant protein d sp d participates in the ...\n",
       "3         endothelin et is a amino acid peptide with div...\n",
       "4         respiratory syncytial virus rsv and pneumonia ...\n",
       "                                ...                        \n",
       "814829     ncov which is a novel coronavirus emerged in ...\n",
       "814830    microbiology laboratories have traditionally r...\n",
       "814831    to present a patient with bilateral conjunctiv...\n",
       "814832    given covid pandemic periodic outpatient asses...\n",
       "814833    objective to examine interhospital variation i...\n",
       "Name: abstract, Length: 814834, dtype: string"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e0c1b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--Chikashi--t5-small-finetuned-cnndm/snapshots/13cf730d52abe6030eb376fd9156ea6474da5448/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"Chikashi/t5-small-finetuned-cnndm\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--Chikashi--t5-small-finetuned-cnndm/snapshots/13cf730d52abe6030eb376fd9156ea6474da5448/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at Chikashi/t5-small-finetuned-cnndm.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n",
      "loading file spiece.model from cache at None\n",
      "loading file tokenizer.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--Chikashi--t5-small-finetuned-cnndm/snapshots/13cf730d52abe6030eb376fd9156ea6474da5448/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--Chikashi--t5-small-finetuned-cnndm/snapshots/13cf730d52abe6030eb376fd9156ea6474da5448/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--Chikashi--t5-small-finetuned-cnndm/snapshots/13cf730d52abe6030eb376fd9156ea6474da5448/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Chikashi/t5-small-finetuned-cnndm'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830359d4",
   "metadata": {},
   "source": [
    "# 2, load and preprocess dataset  and fine tune model\n",
    "- create dataset using pandas\n",
    "- using tokenizer preprocess dataset\n",
    "- finetune model\n",
    "- save finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fc4551bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "asd = {'article':['abd asd', 'asdasff asfasdas'],\n",
    "      'highlights':['asdasd','asdasd']}\n",
    "Dataset.from_dict(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f318ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cnn_dailymail (/Users/kaiyuhe/.cache/huggingface/datasets/cnn_dailymail/1.0.0/1.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfc4ba546e2416d837722d0b75fb8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/kaiyuhe/.cache/huggingface/datasets/cnn_dailymail/1.0.0/1.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de/cache-8c95654dd7312e80.arrow\n"
     ]
    }
   ],
   "source": [
    "# create or load dataset and the clean dataset \n",
    "# onlt two features each sample ['document','summary']\n",
    "dataset = datasets.load_dataset('cnn_dailymail','1.0.0')\n",
    "def flatten_data(example):\n",
    "    return {'document': example['article'],'summary': example['highlights']}\n",
    "def list2samples(example):\n",
    "    documents = []\n",
    "    summaries = []\n",
    "    for sample in zip(example[\"article\"], example[\"summary\"]):\n",
    "        if len(sample[0]) > 0:\n",
    "            documents += sample[0]\n",
    "            summaries += sample[1]\n",
    "    return {\"document\": documents, \"summary\": summaries}\n",
    "dataset = dataset['validation'].map(flatten_data, remove_columns=[\"id\",'highlights','article'])\n",
    "#dataset = dataset.map(list2samples, batched=True)\n",
    "train_data_txt, validation_data_txt = dataset.train_test_split(test_size=0.1).values()\n",
    "encoder_max_length = 512  # demo\n",
    "decoder_max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7717ee6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20835b90b9f9403a86cd1e794bdc77e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6866dac3687d48b69f9c34c56fe584cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize examples\n",
    "def batch_tokenize_preprocess(batch, tokenizer, max_source_length, max_target_length):\n",
    "    source, target = batch[\"document\"], batch[\"summary\"]\n",
    "    source_tokenized = tokenizer(\n",
    "        source, padding=\"max_length\", truncation=True, max_length=max_source_length\n",
    "    )\n",
    "    target_tokenized = tokenizer(\n",
    "        target, padding=\"max_length\", truncation=True, max_length=max_target_length\n",
    "    )\n",
    "\n",
    "    batch = {k: v for k, v in source_tokenized.items()}\n",
    "    # Ignore padding in the loss\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in l]\n",
    "        for l in target_tokenized[\"input_ids\"]\n",
    "    ]\n",
    "    return batch\n",
    "\n",
    "\n",
    "train_data = train_data_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=train_data_txt.column_names,\n",
    ")\n",
    "\n",
    "validation_data = validation_data_txt.map(\n",
    "    lambda batch: batch_tokenize_preprocess(\n",
    "        batch, tokenizer, encoder_max_length, decoder_max_length\n",
    "    ),\n",
    "    batched=True,\n",
    "    remove_columns=validation_data_txt.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e1f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only select 1000 examples for demo\n",
    "train_data = train_data.select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fea8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nh/wmbw_rv57_g2jq_w3v99jyrr0000gn/T/ipykernel_35386/692090678.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"rouge\")\n"
     ]
    }
   ],
   "source": [
    "# metrics for summarization\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "metric = datasets.load_metric(\"rouge\")\n",
    "\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [label.strip() for label in labels]\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "    labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract a few results from ROUGE\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "    prediction_lens = [\n",
    "        np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds\n",
    "    ]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f49940a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/Users/kaiyuhe/opt/anaconda3/envs/huggingface/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 250\n",
      "  Number of trainable parameters = 60506624\n",
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 11:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.860800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.823400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.713500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.624100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=3.785421325683594, metrics={'train_runtime': 706.1081, 'train_samples_per_second': 1.416, 'train_steps_per_second': 0.354, 'total_flos': 135341801472000.0, 'train_loss': 3.785421325683594, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start finetune the model\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"results\",\n",
    "    num_train_epochs=1,  # demo\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=512,  # demo\n",
    "    per_device_eval_batch_size=512,\n",
    "    # learning_rate=3e-05,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.1,\n",
    "    label_smoothing_factor=0.1,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir=\"logs\",\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=validation_data,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20832ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to demotuned_model\n",
      "Configuration saved in demotuned_model/config.json\n",
      "Model weights saved in demotuned_model/pytorch_model.bin\n",
      "tokenizer config file saved in demotuned_model/tokenizer_config.json\n",
      "Special tokens file saved in demotuned_model/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "trainer.save_model('demotuned_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb4f2c9",
   "metadata": {},
   "source": [
    "# 3, Use finetuned model generate candidate summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ac66dd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file demotuned_model/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"demotuned_model\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "loading weights file demotuned_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at demotuned_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "# candidate parameter\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('demotuned_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0c798445",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = dataset['document']\n",
    "reference = dataset['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5b5bfbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(document,truncation=True, \n",
    "                      padding = True, max_length = 512).input_ids\n",
    "input_ids = torch.tensor(input_ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e53f70e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13368, 512])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768b0684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1++2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1\n",
    "b = 2\n",
    "f'{a}++{b}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "92c52827",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7aecdf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a391bcf",
   "metadata": {},
   "source": [
    "### parameters need to specifiy\n",
    "- decoder seq length: max_length\n",
    "- diversity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2a30ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaiyuhe/opt/anaconda3/envs/huggingface/lib/python3.10/site-packages/transformers/generation_beam_search.py:198: UserWarning: Passing `max_length` to BeamSearchScorer is deprecated and has no effect. `max_length` should be passed directly to `beam_search(...)`, `beam_sample(...)`, or `group_beam_search(...)`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# diverse beam search\n",
    "num_return_seqs = 16\n",
    "outputs = model.generate(input_ids,num_beams = num_return_seqs,\n",
    "                         #no_repeat_ngram_size=2,\n",
    "                         diversity_penalty=1.0,\n",
    "                         max_length = 100,\n",
    "                         num_beam_groups = num_return_seqs,\n",
    "    num_return_sequences=num_return_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7f9e9be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 86])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[16:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4d2895c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str = tokenizer.decode(outputs[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "166706b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file config.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--gpt2/snapshots/f27b190eeac4c2302d24068eabf5e9d6044389ae/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file vocab.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--gpt2/snapshots/f27b190eeac4c2302d24068eabf5e9d6044389ae/vocab.json\n",
      "loading file merges.txt from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--gpt2/snapshots/f27b190eeac4c2302d24068eabf5e9d6044389ae/merges.txt\n",
      "loading file tokenizer.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--gpt2/snapshots/f27b190eeac4c2302d24068eabf5e9d6044389ae/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /Users/kaiyuhe/.cache/huggingface/hub/models--gpt2/snapshots/f27b190eeac4c2302d24068eabf5e9d6044389ae/config.json\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer_try = AutoTokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "de9908c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'Ġreally', 'Ġlove', 'Ġto', 'Ġplay']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_try.tokenize('I really love to play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "56fa8c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'really', 'love', 'to', 'play']"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_try.tokenize('I really love to play')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d9338bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('A B')[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fbc31c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_</s>'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([3, 834, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "832f254d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Zully Broussard gave one of her kidneys to a stranger, her generosity paired up with big data. The power multiplied the gift was data processing of genetic profiles from donor-recipient pairs. The chain of surgeries is to be wrapped up Friday.'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(tokenizer.tokenize(test_str)).replace('▁',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04506b",
   "metadata": {},
   "source": [
    "### Start write files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0918f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = document[:16]\n",
    "reference = reference[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5886edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data_for_preprocess(tran_test_val, save_dir,doc,refer,cand):\n",
    "    os.makedirs(save_dir)\n",
    "    cand = [line+'\\n' for line in cand]\n",
    "    doc = [line+'\\n' for line in doc]\n",
    "    refer = [line+'\\n' for line in refer]\n",
    "    with open(f'{save_dir}/{tran_test_val}.out','w') as handle:\n",
    "        handle.writelines(cand)\n",
    "    with open(f'{save_dir}/{tran_test_val}.out.tokenized','w') as handle:\n",
    "        handle.writelines(cand)\n",
    "    with open(f'{save_dir}/{tran_test_val}.source','w') as handle:\n",
    "        handle.writelines(doc)\n",
    "    with open(f'{save_dir}/{tran_test_val}.source.tokenized','w') as handle:\n",
    "        handle.writelines(doc)\n",
    "    with open(f'{save_dir}/{tran_test_val}.target','w') as handle:\n",
    "        handle.writelines(refer)\n",
    "    with open(f'{save_dir}/{tran_test_val}.target.tokenized','w') as handle:\n",
    "        handle.writelines(refer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b36612a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_data_for_preprocess('train','first_write',document, reference, cand_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "715874f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py --src_dir first_write --tgt_dir targetdataset --split train --cand_num 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2148f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling search\n",
    "num_return_seqs = 16\n",
    "outputs = model.generate(input_ids, do_sample=False, num_beams = num_return_seqs,\n",
    "    top_k=50, \n",
    "    top_p=0.95, \n",
    "                         temperature=0.6,\n",
    "                         no_repeat_ngram_size=2,\n",
    "                         diversity_penalty=1.0,\n",
    "                         num_beam_groups = num_return_seqs,\n",
    "    num_return_sequences=num_return_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcae9e4",
   "metadata": {},
   "source": [
    "# 4, Train SimCLS scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb35d40",
   "metadata": {},
   "source": [
    "# 5, Evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": "20",
    "lenType": "20",
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
